{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "from dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sitegts(site_start,site_freqs,duration_len):\n",
    "    # Create approximate labels for dataframe indices when each frequency is being calibrated\n",
    "    # This is based on our two-hour calibration time for each frequency\n",
    "    # ------------------------------------------------\n",
    "    # site_start: (int) index in the all-site-data dataframe labelling when calibration begins\n",
    "    # site_freqs: (list <int>) a list of frequencies being calibrated\n",
    "        # assumptions:\n",
    "            # frequencies are each calibrated for the same amount of time\n",
    "            # frequencies are listed in the order they are calibrated (e.g. if calib. is done in ascending order, freqs. are listed ascending, too)\n",
    "    # duration_len: (int) duration (the number of indices/timestamps) the calibration is occuring\n",
    "        # assumption: the dataframe with site info is recorded in order; i.e. all the rows are in chronological order\n",
    "\n",
    "    # output: a dictionary where key:value is frequency: [start_idx, end_idx] for that frequency during calibration\n",
    "    # ================================================\n",
    "    sitegt = {freq:[0,0] for freq in site_freqs}\n",
    "    for freq in site_freqs:\n",
    "        sitegt[freq][0] = site_start\n",
    "        sitegt[freq][1] = site_start+duration_len\n",
    "        site_start = site_start+duration_len+1\n",
    "    return sitegt\n",
    "\n",
    "def plot_ts_gt(sitegts, freq_data, site_id):\n",
    "    # plot the time series estimated ground truth\n",
    "    # the first plot is the time series and estiamted ground truth\n",
    "    # the second plot is a set of surrounding indices before, during, and after the estimated ground truth for visual clarity\n",
    "    # Note: Audrey will switch to plotly.express in the future\n",
    "    # ------------------------------------------------\n",
    "    # sitegts: a dictionary of dictionaries, see format_sitegts()\n",
    "    # freq_data: the frequency information of the dataframe/series from the dataframe\n",
    "    # site_id: (int)\n",
    "    # output: None\n",
    "    # ================================================\n",
    "    \n",
    "    # this is as many different colors you can assign to frequencies in calibration; add more as needed\n",
    "    colors = ['c','m','y','r','g','b','lime','violet']\n",
    "    site_gt = sitegts[site_id]\n",
    "    fig = plt.figure(figsize=(30,4))\n",
    "    plt.plot(np.arange(len(freq_data)), freq_data,label=\"Frequency TS\")\n",
    "    for i, freq in enumerate(site_gt.keys()):\n",
    "        curr_start = site_gt[freq][0]\n",
    "        curr_end = site_gt[freq][1]\n",
    "        plt.plot(np.arange(curr_start,curr_end), freq_data[curr_start:curr_end], c=colors[i])\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Zoom In\n",
    "    freqs = list(site_gt.keys())\n",
    "    first_freq = freqs[0]\n",
    "    last_freq = freqs[-1]\n",
    "    fig = plt.figure(figsize=(20,4))\n",
    "    range_start = site_gt[first_freq][0]-200\n",
    "    range_end = site_gt[last_freq][1]+200\n",
    "    plt.plot(np.arange(range_start,range_end), freq_data[range_start:range_end], label=\"Frequency TS\")\n",
    "    for i, freq in enumerate(site_gt.keys()):\n",
    "        curr_start = site_gt[freq][0]\n",
    "        curr_end = site_gt[freq][1]\n",
    "        plt.plot(np.arange(curr_start,curr_end), freq_data[curr_start:curr_end], c=colors[i])\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def find_closest_time(data, query_date, query_time='00:00:00'):\n",
    "    # find the closest entry to the query date and time in the dataframe\n",
    "    # ------------------------------------------------\n",
    "        # data: dataframe of the site you're looking at\n",
    "        # query_date: %Y-%m-%d format\n",
    "        # query time: %H:%M:%S format\n",
    "        # output: closest entry in the dataframe timestamp (datetime object), its corresponding dataframe index (int)\n",
    "    # ================================================\n",
    "    date_subset = data[data['timestamp'].str.contains(query_date)]\n",
    "    query_datetime = datetime.strptime(query_date+\" \"+query_time, \"%Y-%m-%d %H:%M:%S\")\n",
    "    closest_timestamp = datetime.strptime(date_subset.iloc[0]['timestamp'], \"%Y-%m-%d %H:%M:%S\")\n",
    "    closest_timeidx = date_subset.iloc[0].index\n",
    "    for i, row in date_subset.iterrows():\n",
    "        curr_date = datetime.strptime(row['timestamp'], \"%Y-%m-%d %H:%M:%S\")\n",
    "        if abs(query_datetime-curr_date) < abs(query_datetime-closest_timestamp):\n",
    "            closest_timestamp = curr_date\n",
    "            closest_timeidx = i\n",
    "    return closest_timestamp, closest_timeidx # errs on the side of being later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # load cached bison data; replace filepath/dataloading as appropriate\n",
    "data = cached_bison_data(\"syncdatabase_011725.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twohr_rate_1_min = 120\n",
    "twohr_rate_5_min = 24\n",
    "\n",
    "# NOTES\n",
    "# union city: 33404, one minute -- '2024-12-17 12:00:00'\n",
    "# siegrist: 33467, five minutes -- '2024-12-17 10:00:00'\n",
    "# canadian: 57740, one minutes -- '2024-12-13 12:00:00'\n",
    "# calumet: 33614, five minutes -- '2024-12-13 12:00:00' 69969 is ~midnight sept 1 2024\n",
    "\n",
    "# OLD -- found starting times based on the above notes by hand\n",
    "# unioncity_start = 259943 \n",
    "# seigrist_start = 66050 \n",
    "# canadian_start = 254170 \n",
    "# calumet_start = 100021\n",
    "\n",
    "# Stage 1: Estimate time stamps for when each stage of calibration is happening given a label for when (date, time) calibration begins for a site\n",
    "# 1. begin with your site id\n",
    "# 2. specify your query start date and time for calibration \n",
    "# 3. find the closest time and date match in the dataframe to your query (default time is 00:00:00 if no time is specified)\n",
    "# 4. hardcode the different frequencies you know are being calibrated # (Stage 2: automate this based on info given in steps 2 and 3 here)\n",
    "# 5. format the estimated ground truth for calibration\n",
    "# 6. plot it\n",
    "\n",
    "unioncity_id = 33404 # 1\n",
    "unioncity_startdate = '2024-12-17' # 2\n",
    "unioncity_startime = '12:00:00'\n",
    "unioncity_timestamp, unioncity_start = find_closest_time(data[data['site_id']==unioncity_id], unioncity_startdate, query_time=unioncity_startime) # 3\n",
    "print(unioncity_timestamp)\n",
    "unioncity_freqs = [46,48,50,52,54,56] # 4\n",
    "unioncity = format_sitegts(unioncity_start,unioncity_freqs,twohr_rate_5_min) # 5\n",
    "\n",
    "siegrist_id = 33467\n",
    "seigrist_startdate = '2024-12-17'\n",
    "seigrist_starttime = '10:00:00'\n",
    "seigrist_timestamp, seigrist_start = find_closest_time(data[data['site_id']==siegrist_id], seigrist_startdate, query_time=seigrist_starttime)\n",
    "seigrist_freqs = [47,49,51,53,55,57] # future: automate based on the above given timestamp\n",
    "print(seigrist_timestamp)\n",
    "siegrist = format_sitegts(seigrist_start,seigrist_freqs,twohr_rate_5_min) \n",
    "\n",
    "canadian_id = 57740\n",
    "canadian_startdate = '2024-12-13'\n",
    "canadian_starttime = '12:00:00'\n",
    "canadian_timestamp, canadian_start = find_closest_time(data[data['site_id']==canadian_id], canadian_startdate, query_time=canadian_starttime)\n",
    "print(canadian_timestamp)\n",
    "canadian_freqs = [44,47,49,51,53,55,57,59] # future: automate based on the above given timestamp\n",
    "canadian = format_sitegts(canadian_start,canadian_freqs,twohr_rate_1_min)\n",
    "\n",
    "calumet_id = 33614\n",
    "calumet_startdate = '2024-12-13'\n",
    "calumet_starttime = '12:00:00'\n",
    "calumet_timestamp, calumet_start = find_closest_time(data[data['site_id']==calumet_id], calumet_startdate, query_time=calumet_starttime)\n",
    "print(calumet_timestamp)\n",
    "calumet_freqs = [49,51,53,55] # future: automate based on the above given timestamp\n",
    "calumet = format_sitegts(calumet_start,calumet_freqs,twohr_rate_5_min)\n",
    "\n",
    "sitegts = {unioncity_id:unioncity, siegrist_id:siegrist, canadian_id:canadian, calumet_id:calumet}\n",
    "\n",
    "# QUICK COMMANDS -- feel free to ignore\n",
    "# print(data[data['site_id']==33614]) # look at the data for a given site\n",
    "# s_temp = 259943 \n",
    "# print(data[s_temp:s_temp+twohr_rate_1_min]) # quickly check the two hour duration based off a start index & given sampling rate\n",
    "# print(data[data['timestamp']=='2024-12-17 12:00:02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site_id in sitegts.keys(): # 6\n",
    "    print(site_id)\n",
    "    freq_data = data['frequency']\n",
    "    plot_ts_gt(sitegts, freq_data, site_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can rename these functions later\n",
    "\n",
    "def ryan_format(data, ryan_sites_info, audrey_sitegts):\n",
    "    # takes Audrey's info in Audrey dictionaries-using-dataframe-indices format and converts it to Ryan's timestamp format\n",
    "    # ------------------------------------------------\n",
    "    # data: dataframe of all site info\n",
    "    # ryan_sites_info: copied from https://github.com/neuralix-ai/dev_RyanMercer/blob/dev/notebooks/Customers/Bison/2024-12-29_Bison_PumpCurve_x-axisHealth_calibrated_alert.ipynb\n",
    "    # audrey_sitegts: audrey's format of using dataframe indices\n",
    "    # output: start-time and end-time and frequency data is recorded in Ryan's site_info format consistent with ryan_sites_info\n",
    "    # ================================================\n",
    "\n",
    "    ryan_format_sitegts = deepcopy(ryan_sites_info) # we need to keep the rest of the structure of Ryan's sites_info (enable, num_pumps, etc.)\n",
    "    format_calib_stage = []\n",
    "    for site in ryan_format_sitegts: # for each site in the database...\n",
    "        site_id = site['site_id'] # for each site in Ryan's gt,\n",
    "        curr_site_gts = audrey_sitegts[site_id] # find the site estimated gt in Audrey's idx format dictionary\n",
    "        for freq in curr_site_gts.keys(): # for each frequency at a site...\n",
    "            tmp = {}\n",
    "            tmp['frequency'] = freq\n",
    "            start_and_end = curr_site_gts[freq]\n",
    "            start_timestamp = data.iloc[start_and_end[0]]['timestamp']\n",
    "            end_timestamp = data.iloc[start_and_end[1]]['timestamp']\n",
    "            tmp['start_time'] = start_timestamp\n",
    "            tmp['end_time'] = end_timestamp\n",
    "            format_calib_stage.append(tmp)\n",
    "        site['calibration_stages'] = format_calib_stage # ...now replace the info now that it's in Ryan's format\n",
    "    return ryan_format_sitegts\n",
    "\n",
    "\n",
    "def ryan_site_info_to_audrey_format(data, ryan_cached_gt,sampling_rates):\n",
    "    # takes in the GT format from Ryan and converts it to the format Audrey uses in the plots above\n",
    "    # ------------------------------------------------\n",
    "    # data: dataframe of all site info\n",
    "    # ryan_cached_gt: copied from https://github.com/neuralix-ai/dev_RyanMercer/blob/dev/notebooks/Customers/Bison/2024-12-29_Bison_PumpCurve_x-axisHealth_calibrated_alert.ipynb\n",
    "    # sampling_rates: sampling rates for each site (hardcoded)\n",
    "    # output: audrey-format dictionaries about site info\n",
    "    # ================================================\n",
    "    audrey_format = {}\n",
    "    for site in ryan_cached_gt:\n",
    "        site_id = site['site_id']\n",
    "        frequencies = []\n",
    "        for stage in site['calibration_stages']:\n",
    "            frequencies.append(stage['frequency'])\n",
    "            listed_start = stage['start_time'].split(\" \")\n",
    "            startdate = listed_start[0]\n",
    "            starttime = listed_start[1]\n",
    "            _, index = find_closest_time(data[data['site_id']==site_id], startdate, query_time=starttime)\n",
    "        site_estimatedgt = format_sitegts(index,frequencies,sampling_rates[site_id])\n",
    "        audrey_format[site_id] = site_estimatedgt\n",
    "    return audrey_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from sites_info: \n",
    "# https://github.com/neuralix-ai/dev_RyanMercer/blob/dev/notebooks/Customers/Bison/2024-12-29_Bison_PumpCurve_x-axisHealth_calibrated_alert.ipynb\n",
    "ryan_cached_gt = cached_site_info() \n",
    "audrey_sitegts = deepcopy(sitegts)\n",
    "\n",
    "print(ryan_cached_gt)\n",
    "replace_this_every_week_ryan = ryan_format(data, ryan_cached_gt, audrey_sitegts)\n",
    "print(replace_this_every_week_ryan)\n",
    "\n",
    "# examine how the timestamps change from \"my rough guess was about noon\" --> \"the precise time in the dataframe is 12:00:19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rates = {33404:twohr_rate_1_min, 33467:twohr_rate_5_min, 57740:twohr_rate_1_min, 33614:twohr_rate_5_min}\n",
    "ryan_cached_to_audrey_format = ryan_site_info_to_audrey_format(data, ryan_cached_gt, sampling_rates)\n",
    "print(ryan_cached_to_audrey_format)\n",
    "replace_every_week_to_audrey_format = ryan_site_info_to_audrey_format(data, replace_this_every_week_ryan, sampling_rates)\n",
    "print(replace_every_week_to_audrey_format)\n",
    "\n",
    "# these are a tad different because ...\n",
    "# ... I made time stamps mutually exclusive to a particular calibration frequency, whereas a calibration stage could start at 14:00:00 AND another could begin at 14:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bison",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
